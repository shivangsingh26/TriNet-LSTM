{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND ANALYZE DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== EMOTION DATASET ====================\n",
      "\n",
      "👉 Shape: (416809, 3)\n",
      "\n",
      "👉 Columns: ['Unnamed: 0', 'text', 'label']\n",
      "\n",
      "👉 Head:\n",
      "   Unnamed: 0                                               text  label\n",
      "0           0      i just feel really helpless and heavy hearted      4\n",
      "1           1  ive enjoyed being able to slouch about relax a...      0\n",
      "2           2  i gave up my internship with the dmrg and am f...      4\n",
      "3           3                         i dont know i feel so lost      0\n",
      "4           4  i am a kindergarten teacher and i am thoroughl...      4\n",
      "\n",
      "==================== VIOLENCE DATASET ====================\n",
      "\n",
      "👉 Shape: (39650, 3)\n",
      "\n",
      "👉 Columns: ['Tweet_ID', 'tweet', 'type']\n",
      "\n",
      "👉 Head:\n",
      "      Tweet_ID                                              tweet  \\\n",
      "0  ID_0022DWKP  Had a dream i got raped last night. By a guy i...   \n",
      "1  ID_00395QYM  he thought the word raped means sex and told m...   \n",
      "2  ID_003EOSSF  She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...   \n",
      "3  ID_004BBHOD  I was sexually abused for 3 years at age 4 to ...   \n",
      "4  ID_004F7516  Chessy Prout can do better by telling the trut...   \n",
      "\n",
      "              type  \n",
      "0  sexual_violence  \n",
      "1  sexual_violence  \n",
      "2  sexual_violence  \n",
      "3  sexual_violence  \n",
      "4  sexual_violence  \n",
      "\n",
      "==================== HATE SPEECH DATASET ====================\n",
      "\n",
      "👉 Shape: (24783, 7)\n",
      "\n",
      "👉 Columns: ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither', 'class', 'tweet']\n",
      "\n",
      "👉 Head:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "emotion_df = pd.read_csv(\"data/emotions_dataset.csv\")\n",
    "hate_df = pd.read_csv(\"data/hate_speech_dataset.csv\")\n",
    "violence_df = pd.read_csv(\"data/violence_dataset/violence_dataset.csv\")\n",
    "\n",
    "# Function to display dataset info\n",
    "def display_dataset_info(name, df):\n",
    "    print(f\"\\n{'='*20} {name.upper()} DATASET {'='*20}\")\n",
    "    print(f\"\\n👉 Shape: {df.shape}\")\n",
    "    print(f\"\\n👉 Columns: {df.columns.tolist()}\")\n",
    "    print(f\"\\n👉 Head:\\n{df.head()}\")\n",
    "\n",
    "# Display info for each dataset\n",
    "display_dataset_info(\"Emotion\", emotion_df)\n",
    "display_dataset_info(\"Violence\", violence_df)\n",
    "display_dataset_info(\"Hate Speech\", hate_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "\n",
    "emotion_df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "violence_df.drop(columns=['Tweet_ID'], inplace=True, errors='ignore')\n",
    "hate_df = hate_df[['tweet', 'class']] # Didnt use drop as classes to drop were many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== EMOTION DATASET ====================\n",
      "\n",
      "👉 Shape: (416809, 2)\n",
      "\n",
      "👉 Columns: ['text', 'label']\n",
      "\n",
      "👉 Head:\n",
      "                                                text  label\n",
      "0      i just feel really helpless and heavy hearted      4\n",
      "1  ive enjoyed being able to slouch about relax a...      0\n",
      "2  i gave up my internship with the dmrg and am f...      4\n",
      "3                         i dont know i feel so lost      0\n",
      "4  i am a kindergarten teacher and i am thoroughl...      4\n",
      "\n",
      "==================== VIOLENCE DATASET ====================\n",
      "\n",
      "👉 Shape: (39650, 2)\n",
      "\n",
      "👉 Columns: ['tweet', 'type']\n",
      "\n",
      "👉 Head:\n",
      "                                               tweet             type\n",
      "0  Had a dream i got raped last night. By a guy i...  sexual_violence\n",
      "1  he thought the word raped means sex and told m...  sexual_violence\n",
      "2  She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...  sexual_violence\n",
      "3  I was sexually abused for 3 years at age 4 to ...  sexual_violence\n",
      "4  Chessy Prout can do better by telling the trut...  sexual_violence\n",
      "\n",
      "==================== HATE SPEECH DATASET ====================\n",
      "\n",
      "👉 Shape: (24783, 2)\n",
      "\n",
      "👉 Columns: ['tweet', 'class']\n",
      "\n",
      "👉 Head:\n",
      "                                               tweet  class\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n"
     ]
    }
   ],
   "source": [
    "def display_dataset_info(name, df):\n",
    "    print(f\"\\n{'='*20} {name.upper()} DATASET {'='*20}\")\n",
    "    print(f\"\\n👉 Shape: {df.shape}\")\n",
    "    print(f\"\\n👉 Columns: {df.columns.tolist()}\")\n",
    "    print(f\"\\n👉 Head:\\n{df.head()}\")\n",
    "\n",
    "# Display info for each dataset\n",
    "display_dataset_info(\"Emotion\", emotion_df)\n",
    "display_dataset_info(\"Violence\", violence_df)\n",
    "display_dataset_info(\"Hate Speech\", hate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that column names of labels of all datasets are not consistent.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns for consistency\n",
    "#emotion_df already has 'text' and 'label' columns\n",
    "hate_df.rename(columns={'tweet':'text', 'class':'label'}, inplace=True)  \n",
    "violence_df.rename(columns={'tweet': 'text', 'type':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label'], dtype='object')\n",
      "Index(['text', 'label'], dtype='object')\n",
      "Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(emotion_df.columns)\n",
    "print(violence_df.columns)\n",
    "print(hate_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(text     0\n",
       " label    0\n",
       " dtype: int64,\n",
       " text     0\n",
       " label    0\n",
       " dtype: int64,\n",
       " text     0\n",
       " label    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.isna().sum() , violence_df.isna().sum(), hate_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!! No null values!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416809, 2), (39650, 2), (24783, 2))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.shape, violence_df.shape, hate_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that #rows are highly inconsistent here,\n",
    "\n",
    "So we can select 20k rows from each dataset and build 3 new datasets.\n",
    "\n",
    "This rows should be distributed equally among all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 1    141067\n",
       " 0    121187\n",
       " 3     57317\n",
       " 4     47712\n",
       " 2     34554\n",
       " 5     14972\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " sexual_violence                 32648\n",
       " Physical_violence                5946\n",
       " emotional_violence                651\n",
       " economic_violence                 217\n",
       " Harmful_Traditional_practice      188\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 1    19190\n",
       " 2     4163\n",
       " 0     1430\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.label.value_counts(), violence_df.label.value_counts(), hate_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Firstly for Emotions dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = pd.DataFrame()\n",
    "\n",
    "for i in emotion_df.label.unique():\n",
    "    subset = emotion_df[emotion_df.label == i].sample(n=2000, random_state=42) #extracting random 2k rows from each class.\n",
    "    e_df = pd.concat([e_df, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "4    2000\n",
      "0    2000\n",
      "2    2000\n",
      "1    2000\n",
      "5    2000\n",
      "3    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_df = e_df.copy()\n",
    "print(emotion_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Secondly for Violence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "sexual_violence                 32648\n",
       "Physical_violence                5946\n",
       "emotional_violence                651\n",
       "economic_violence                 217\n",
       "Harmful_Traditional_practice      188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a huge imbalance we need to balance it accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since emotional_violence, economic_violence, and political_violence are low frequency classes, \n",
    "\n",
    "we will use all the data for these classes.\n",
    "\n",
    "We will also keep all of physical_violence, \n",
    "\n",
    "and for sexual_violence we will keep 4998 random rows to get the total row count to 12000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Physical_violence               5946\n",
      "sexual_violence                 4998\n",
      "emotional_violence               651\n",
      "economic_violence                217\n",
      "Harmful_Traditional_practice     188\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#creating new column for 'sexual_violence' to balance the dataset, and appending it to the existing violence_df\n",
    "sexual_violence = violence_df[violence_df.label == 'sexual_violence'].sample(n=4998, random_state=42)\n",
    "violence_df = pd.concat([violence_df[violence_df.label != 'sexual_violence'], sexual_violence], ignore_index=True)\n",
    "print(violence_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lastly for Hate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here also we will take all of 2,0 classes and \n",
    "\n",
    "for 1st class we use 6407 rows to complete the dataset size of 12k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    6407\n",
      "2    4163\n",
      "0    1430\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#creating new column for 1 to balance the dataset, and appending it to the existing hate_df\n",
    "\n",
    "offensive_speech = hate_df[hate_df.label == 1].sample(n=6407, random_state=42)\n",
    "hate_df = pd.concat([hate_df[hate_df.label !=1], offensive_speech], ignore_index=True)\n",
    "print(hate_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 2), (12000, 2), (12000, 2))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.shape, violence_df.shape, hate_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all our new df shapes are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have randomly selected our dataset, their indices are random as well.\n",
    "\n",
    "So we need to reset the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index for all datasets\n",
    "emotion_df.reset_index(drop=True, inplace=True)\n",
    "violence_df.reset_index(drop=True, inplace=True)\n",
    "hate_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== EMOTION DATASET ====================\n",
      "\n",
      "👉 Head:\n",
      "                                                text  label\n",
      "0  i feel that it creates a suspicious environmen...      4\n",
      "1               i feel reluctant asking for anything      4\n",
      "2  i am afraid to really show what i feel because...      4\n",
      "3  i think he feels a little helpless in all this...      4\n",
      "4                          i certainly feel tortured      4\n",
      "\n",
      "==================== VIOLENCE DATASET ====================\n",
      "\n",
      "👉 Head:\n",
      "                                                text              label\n",
      "0  My Husband Beats Me Frequently, Wife Tells Cou...  Physical_violence\n",
      "1  Best thing for me to do, is remain silent when...  Physical_violence\n",
      "2  My husband will never beat me, Bambam denies r...  Physical_violence\n",
      "3  theyre like, i just wanna be a baby maker with...  Physical_violence\n",
      "4  I was in England for a week, the longest I’ve ...  Physical_violence\n",
      "\n",
      "==================== HATE SPEECH DATASET ====================\n",
      "\n",
      "👉 Head:\n",
      "                                                text  label\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
      "1    \" momma said no pussy cats inside my doghouse \"      2\n",
      "2  \"@Addicted2Guys: -SimplyAddictedToGuys http://...      2\n",
      "3  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...      2\n",
      "4  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...      2\n"
     ]
    }
   ],
   "source": [
    "# Function to display dataset info\n",
    "def display_dataset_info(name, df):\n",
    "    print(f\"\\n{'='*20} {name.upper()} DATASET {'='*20}\")\n",
    "    # print(f\"\\n👉 Shape: {df.shape}\")\n",
    "    # print(f\"\\n👉 Columns: {df.columns.tolist()}\")\n",
    "    print(f\"\\n👉 Head:\\n{df.head()}\")\n",
    "\n",
    "# Display info for each dataset\n",
    "display_dataset_info(\"Emotion\", emotion_df)\n",
    "display_dataset_info(\"Violence\", violence_df)\n",
    "display_dataset_info(\"Hate Speech\", hate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the indices are consistent as well.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABEL ENCODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont need encoding for Emotion and Hate Speech Datasets, We only need to do it for Violence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "violence_df['label'] = label_encoder.fit_transform(violence_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5946\n",
       "4    4998\n",
       "3     651\n",
       "2     217\n",
       "0     188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now labels in Violence Dataset have been encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP WORDS REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivangsingh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivangsingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly downloading stopwords and punctuations\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t', 'own', 'than', 'he', 'yours', 'there', 'on', 've', \"we'd\", 'nor', 'a', \"you'll\", 'isn', 'be', 'wasn', 'again', 'above', 'very', \"i've\", 'off', \"she's\", \"he's\", 'because', \"mustn't\", 'themselves', 'with', 'if', 'not', 'once', \"wouldn't\", 'at', 'were', 'd', \"i'll\", 'or', 'needn', 'have', 'both', 'weren', 'hers', 'down', \"haven't\", 'shan', 'as', 'had', 'into', 'been', 'hasn', \"isn't\", \"i'm\", 'having', \"you're\", 'further', 'between', 'should', \"needn't\", 'our', 'but', 'your', 'during', 'does', 'himself', \"we've\", \"we're\", 'too', 'shouldn', 'can', \"should've\", 'didn', 'did', 'ourselves', \"they'll\", \"couldn't\", 'herself', 'my', 'in', 'few', 'by', 'me', 'mustn', 'through', 'i', 'wouldn', 'y', \"you've\", \"they'd\", 'below', 'now', 'them', 'from', 'it', \"hadn't\", 'when', 'myself', 'ain', 'are', 'each', 'o', 'couldn', 'of', 'and', 'you', 'him', 'then', 'yourself', 'other', 'any', \"she'll\", 'such', 'the', 'whom', 'about', 'for', 'ma', 'these', 'to', \"didn't\", 'doesn', 'she', \"we'll\", 'what', 'out', \"he'll\", 'after', 'am', 'over', 'theirs', \"hasn't\", 'his', 'aren', 'they', 'm', \"he'd\", \"it'd\", 'while', 'all', 'hadn', \"it's\", 'how', 'ours', 'their', 'who', 'only', 'so', 'haven', \"aren't\", 'this', 'being', 'that', 'where', 'same', 'yourselves', 'we', \"mightn't\", \"shouldn't\", 'why', \"don't\", 'was', 'against', \"they're\", \"won't\", 'won', 'is', \"i'd\", 'will', 'her', 'here', \"that'll\", 'more', 'itself', 'mightn', 'most', \"she'd\", 'until', 'some', 'an', 'those', 'its', 'do', \"you'd\", \"doesn't\", \"shan't\", 'under', \"wasn't\", 'll', 'has', 'doing', 're', \"they've\", 'just', 'no', 's', \"weren't\", 'don', 'which', 'up', 'before', \"it'll\"}\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "#loading stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 198 stopwords currently present in the english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in '/Users/shivangsingh/nltk_data/corpora/stopwords'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords Removal Function\n",
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Lets apply the stopwords removal function to each dataset\n",
    "emotion_df['text'] = emotion_df['text'].apply(remove_stopwords)\n",
    "violence_df['text'] = violence_df['text'].apply(remove_stopwords)\n",
    "hate_df['text'] = hate_df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0  i feel that it creates a suspicious environmen...      4\n",
       " 1               i feel reluctant asking for anything      4\n",
       " 2  i am afraid to really show what i feel because...      4\n",
       " 3  i think he feels a little helpless in all this...      4\n",
       " 4                          i certainly feel tortured      4,\n",
       "                                                 text  label\n",
       " 0  My Husband Beats Me Frequently, Wife Tells Cou...      1\n",
       " 1  Best thing for me to do, is remain silent when...      1\n",
       " 2  My husband will never beat me, Bambam denies r...      1\n",
       " 3  theyre like, i just wanna be a baby maker with...      1\n",
       " 4  I was in England for a week, the longest I’ve ...      1,\n",
       "                                                 text  label\n",
       " 0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       " 1    \" momma said no pussy cats inside my doghouse \"      2\n",
       " 2  \"@Addicted2Guys: -SimplyAddictedToGuys http://...      2\n",
       " 3  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...      2\n",
       " 4  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...      2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.head(), violence_df.head(), hate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION AND PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([emotion_df['text'],  violence_df['text'], hate_df['text']]))\n",
    "# Convert texts to sequences(of numbers. eg i am happy ----> [1, 2, 3, 4] if the words are mapped to these numbers)\n",
    "emotion_sequences = tokenizer.texts_to_sequences(emotion_df['text'])\n",
    "violence_sequences = tokenizer.texts_to_sequences(violence_df['text'])\n",
    "hate_sequences = tokenizer.texts_to_sequences(hate_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am afraid to really show what i feel because im terrified of having it thrown back in my face',\n",
       " [1,\n",
       "  53,\n",
       "  517,\n",
       "  3,\n",
       "  83,\n",
       "  317,\n",
       "  50,\n",
       "  1,\n",
       "  12,\n",
       "  46,\n",
       "  56,\n",
       "  980,\n",
       "  10,\n",
       "  217,\n",
       "  15,\n",
       "  2304,\n",
       "  119,\n",
       "  11,\n",
       "  7,\n",
       "  302])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df['text'].iloc[2], emotion_sequences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we will add padding to the sequences to make them of equal length\n",
    "max_length = 50  # Define the maximum length of sequences\n",
    "emotion_padded = pad_sequences(emotion_sequences, maxlen=max_length, padding='post')\n",
    "violence_padded = pad_sequences(violence_sequences, maxlen=max_length, padding='post')\n",
    "hate_padded = pad_sequences(hate_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am afraid to really show what i feel because im terrified of having it thrown back in my face',\n",
       " array([   1,   53,  517,    3,   83,  317,   50,    1,   12,   46,   56,\n",
       "         980,   10,  217,   15, 2304,  119,   11,    7,  302,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df['text'].iloc[2], emotion_padded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now as our text is in numpy array format, lets convert the labels to numpy array as well\n",
    "emotion_labels = np.array(emotion_df['label'])\n",
    "violence_labels = np.array(violence_df['label'])\n",
    "hate_labels = np.array(hate_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 4, 4, ..., 3, 3, 3], shape=(12000,)),\n",
       " array([1, 1, 1, ..., 4, 4, 4], shape=(12000,)),\n",
       " array([2, 2, 2, ..., 1, 1, 1], shape=(12000,)))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_labels, violence_labels, hate_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining inputs for each dataset\n",
    "\n",
    "emotion_inputs = emotion_padded\n",
    "violence_inputs = violence_padded\n",
    "hate_inputs = hate_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining multiple input layers for each task\n",
    "\n",
    "emotion_input_layer = keras.layers.Input(shape=(max_length,), name='emotion_input')\n",
    "violence_input_layer = keras.layers.Input(shape=(max_length,), name='violence_input')\n",
    "hate_input_layer = keras.layers.Input(shape=(max_length,), name='hate_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining shared embedding layer\n",
    "embedding_layer = keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY EMBEDDING LAYER TO EACH INPUT\n",
    "emotion_embedding = embedding_layer(emotion_input_layer)\n",
    "violence_embedding = embedding_layer(violence_input_layer)\n",
    "hate_embedding = embedding_layer(hate_input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHARED LSTM LAYER\n",
    "shared_lstm = keras.layers.LSTM(64, return_sequences=True) \n",
    "#return sequences=True as we have different tasks (generally kept to True if there are multiple LSTM layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_lstm = shared_lstm(emotion_embedding)\n",
    "violence_lstm = shared_lstm(violence_embedding)\n",
    "hate_lstm = shared_lstm(hate_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHARED GLOBAL AVERAGE POOLING LAYER AND DROPOUT LAYER\n",
    "\n",
    "shared_pooling = keras.layers.GlobalAveragePooling1D()\n",
    "shared_droput = keras.layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking all layers together for each task.\n",
    "emotion_features = shared_droput(shared_pooling(emotion_lstm))\n",
    "violence_features = shared_droput(shared_pooling(violence_lstm))\n",
    "hate_features = shared_droput(shared_pooling(hate_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emotion classes: 6\n",
      "Number of violence classes: 5\n",
      "Number of hate classes: 3\n"
     ]
    }
   ],
   "source": [
    "#Checking number of labels in each dataset\n",
    "num_emotion_classes = len(emotion_df['label'].unique())\n",
    "num_violence_classes = len(violence_df['label'].unique())\n",
    "num_hate_classes = len(hate_df['label'].unique())\n",
    "\n",
    "print(f\"Number of emotion classes: {num_emotion_classes}\")\n",
    "print(f\"Number of violence classes: {num_violence_classes}\")\n",
    "print(f\"Number of hate classes: {num_hate_classes}\")\n",
    "\n",
    "#This helps us to define the number of neurons for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING SEPERATE OUTPUT LAYERS\n",
    "emotion_output = keras.layers.Dense(6, activation='softmax', name = 'emotion_output')(emotion_features)  # 6 classes for emotion dataset\n",
    "violence_output = keras.layers.Dense(5, activation='softmax', name = 'violence_output')(violence_features)  # 5 classes for violence dataset\n",
    "hate_output = keras.layers.Dense(3, activation='softmax', name = 'hate_output')(hate_features)  # 3 classes for hate speech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model with multiple inputs, outputs\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[emotion_input_layer, violence_input_layer, hate_input_layer],\n",
    "    outputs=[emotion_output, violence_output, hate_output]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = {\n",
    "        'emotion_output': 'sparse_categorical_crossentropy',\n",
    "        'violence_output': 'sparse_categorical_crossentropy',\n",
    "        'hate_output': 'sparse_categorical_crossentropy'\n",
    "    },#defining loss functions seperately for each task.\n",
    "    metrics = {\n",
    "        'emotion_output': 'accuracy',\n",
    "        'violence_output': 'accuracy',\n",
    "        'hate_output': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ emotion_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ violence_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hate_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,603,712</span> │ emotion_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ violence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ hate_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emotion_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ violence_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hate_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ emotion_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ violence_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hate_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m5,603,712\u001b[0m │ emotion_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ violence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ hate_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ lstm[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emotion_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m390\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ violence_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dropout[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hate_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,654,030</span> (21.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,654,030\u001b[0m (21.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,654,030</span> (21.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,654,030\u001b[0m (21.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - emotion_output_accuracy: 0.2244 - emotion_output_loss: 1.6635 - hate_output_accuracy: 0.5199 - hate_output_loss: 0.9542 - loss: 3.3336 - violence_output_accuracy: 0.7535 - violence_output_loss: 0.7160 - val_emotion_output_accuracy: 0.1538 - val_emotion_output_loss: 4.2308 - val_hate_output_accuracy: 0.8662 - val_hate_output_loss: 0.4168 - val_loss: 4.7919 - val_violence_output_accuracy: 0.9571 - val_violence_output_loss: 0.1443\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - emotion_output_accuracy: 0.6772 - emotion_output_loss: 0.8569 - hate_output_accuracy: 0.8686 - hate_output_loss: 0.3992 - loss: 1.3951 - violence_output_accuracy: 0.9498 - violence_output_loss: 0.1389 - val_emotion_output_accuracy: 0.1621 - val_emotion_output_loss: 5.2343 - val_hate_output_accuracy: 0.8229 - val_hate_output_loss: 0.4104 - val_loss: 5.7299 - val_violence_output_accuracy: 0.9812 - val_violence_output_loss: 0.0852\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - emotion_output_accuracy: 0.8766 - emotion_output_loss: 0.4282 - hate_output_accuracy: 0.9074 - hate_output_loss: 0.2864 - loss: 0.7888 - violence_output_accuracy: 0.9746 - violence_output_loss: 0.0742 - val_emotion_output_accuracy: 0.1508 - val_emotion_output_loss: 6.2898 - val_hate_output_accuracy: 0.8225 - val_hate_output_loss: 0.4264 - val_loss: 6.8500 - val_violence_output_accuracy: 0.9758 - val_violence_output_loss: 0.1338\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - emotion_output_accuracy: 0.9169 - emotion_output_loss: 0.3015 - hate_output_accuracy: 0.9400 - hate_output_loss: 0.1904 - loss: 0.5460 - violence_output_accuracy: 0.9794 - violence_output_loss: 0.0541 - val_emotion_output_accuracy: 0.1488 - val_emotion_output_loss: 7.0168 - val_hate_output_accuracy: 0.8517 - val_hate_output_loss: 0.4317 - val_loss: 7.5445 - val_violence_output_accuracy: 0.9842 - val_violence_output_loss: 0.0960\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - emotion_output_accuracy: 0.9428 - emotion_output_loss: 0.2117 - hate_output_accuracy: 0.9638 - hate_output_loss: 0.1305 - loss: 0.3763 - violence_output_accuracy: 0.9903 - violence_output_loss: 0.0341 - val_emotion_output_accuracy: 0.1525 - val_emotion_output_loss: 7.4737 - val_hate_output_accuracy: 0.8612 - val_hate_output_loss: 0.5269 - val_loss: 8.0984 - val_violence_output_accuracy: 0.9771 - val_violence_output_loss: 0.0977\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - emotion_output_accuracy: 0.9625 - emotion_output_loss: 0.1407 - hate_output_accuracy: 0.9712 - hate_output_loss: 0.0966 - loss: 0.2569 - violence_output_accuracy: 0.9980 - violence_output_loss: 0.0196 - val_emotion_output_accuracy: 0.1525 - val_emotion_output_loss: 7.2153 - val_hate_output_accuracy: 0.8213 - val_hate_output_loss: 0.5708 - val_loss: 7.9209 - val_violence_output_accuracy: 0.9613 - val_violence_output_loss: 0.1349\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - emotion_output_accuracy: 0.9687 - emotion_output_loss: 0.1208 - hate_output_accuracy: 0.9748 - hate_output_loss: 0.1004 - loss: 0.2352 - violence_output_accuracy: 0.9983 - violence_output_loss: 0.0140 - val_emotion_output_accuracy: 0.1546 - val_emotion_output_loss: 7.9685 - val_hate_output_accuracy: 0.7992 - val_hate_output_loss: 0.7142 - val_loss: 8.8513 - val_violence_output_accuracy: 0.9638 - val_violence_output_loss: 0.1687\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - emotion_output_accuracy: 0.9651 - emotion_output_loss: 0.1195 - hate_output_accuracy: 0.9837 - hate_output_loss: 0.0678 - loss: 0.1986 - violence_output_accuracy: 0.9987 - violence_output_loss: 0.0112 - val_emotion_output_accuracy: 0.1458 - val_emotion_output_loss: 8.4720 - val_hate_output_accuracy: 0.8121 - val_hate_output_loss: 0.7479 - val_loss: 9.2955 - val_violence_output_accuracy: 0.9767 - val_violence_output_loss: 0.0757\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - emotion_output_accuracy: 0.9758 - emotion_output_loss: 0.0875 - hate_output_accuracy: 0.9878 - hate_output_loss: 0.0482 - loss: 0.1426 - violence_output_accuracy: 0.9995 - violence_output_loss: 0.0069 - val_emotion_output_accuracy: 0.1500 - val_emotion_output_loss: 8.5364 - val_hate_output_accuracy: 0.7808 - val_hate_output_loss: 0.8939 - val_loss: 9.6135 - val_violence_output_accuracy: 0.9638 - val_violence_output_loss: 0.1832\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - emotion_output_accuracy: 0.9782 - emotion_output_loss: 0.0775 - hate_output_accuracy: 0.9906 - hate_output_loss: 0.0376 - loss: 0.1203 - violence_output_accuracy: 0.9991 - violence_output_loss: 0.0052 - val_emotion_output_accuracy: 0.1412 - val_emotion_output_loss: 9.2408 - val_hate_output_accuracy: 0.8575 - val_hate_output_loss: 0.6339 - val_loss: 10.0333 - val_violence_output_accuracy: 0.9625 - val_violence_output_loss: 0.1586\n"
     ]
    }
   ],
   "source": [
    "# Train the model with seperate inputs and outputs\n",
    "train_history = model.fit(\n",
    "    x = {'emotion_input': emotion_inputs,\n",
    "         'violence_input': violence_inputs,\n",
    "         'hate_input': hate_inputs},\n",
    "    y = {'emotion_output': emotion_labels,\n",
    "         'violence_output': violence_labels,\n",
    "         'hate_output': hate_labels},\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTriNetLSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
